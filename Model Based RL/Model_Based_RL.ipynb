{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete State and Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2 Actions, 3 States, 3 States)\n",
    "\n",
    "transition_mat = [[\n",
    "    [0.1, 0.5, 0.4],\n",
    "    [0.2, 0.7, 0.1],\n",
    "    [0.3, 0.3, 0.4]\n",
    "],[\n",
    "    [0.5, 0.2, 0.3],\n",
    "    [0.8, 0.1, 0.1],\n",
    "    [0.2, 0.7, 0.1]\n",
    "]]\n",
    "\n",
    "reward_dist = [tfd.Normal(10, 5), tfd.Normal(3, 3), tfd.Normal(2, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = tfd.Categorical(probs=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROUNDS = 1_0\n",
    "state = 0\n",
    "hist = []\n",
    "\n",
    "\n",
    "for t in range(N_ROUNDS):\n",
    "    action = policy.sample()\n",
    "    next_state = tfd.Categorical(transition_mat[action][state]).sample()\n",
    "    reward = reward_dist[next_state].sample()\n",
    "\n",
    "    hist.append({\"state\":int(state), \"action\":int(action), \"next_state\":int(next_state), \"reward\":int(reward)})\n",
    "\n",
    "    state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>action</th>\n",
       "      <th>next_state</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state  action  next_state  reward\n",
       "0      0       0           2       2\n",
       "1      2       1           0       7\n",
       "2      0       1           2       2\n",
       "3      2       1           1       5\n",
       "4      1       1           1       3\n",
       "5      1       0           0       1\n",
       "6      0       0           0      14\n",
       "7      0       0           2       1\n",
       "8      2       0           0       6\n",
       "9      0       1           0      15"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(hist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous State, Discrete Action, deterministic transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reward(state):\n",
    "    return - np.sum(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.array([1000, 1000, 1000, 1000]) # some warehouse quantities\n",
    "demand_t = np.array([500, 200, 300, 400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplier = np.array([\n",
    "    [200, 200, 200, 200],\n",
    "    [400, 200,300,500],\n",
    "    [700, 100, 200, 200]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_transition(state, action):\n",
    "    return state + supplier[action] - demand_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def T(s, a, w_t):\n",
    "    \"\"\"\n",
    "    predict the next possible state s_prime\n",
    "    \"\"\"\n",
    "    next_state = np.dot([s,a], w_t)\n",
    "\n",
    "    return s ** w_t + a ** w_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.Variable(3.0)\n",
    "a = tf.Variable(2.0)\n",
    "w_t = tf.Variable(1.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = T(s,a,w_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_dx = tape.gradient(y, w_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R(s,a):\n",
    "    \"\"\"\n",
    "    predicts the next possible reward based on the state that the agent was in and the action\n",
    "    he took\n",
    "    \"\"\"\n",
    "    reward = None\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(s,a):\n",
    "    \"\"\"\n",
    "    calculates the Q Value\n",
    "    \"\"\"\n",
    "    q_val = None\n",
    "\n",
    "    return q_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROUNDS = 1000\n",
    "alpha_t = 0.1\n",
    "alpha_r = 0.1\n",
    "alpha_q = 0.1\n",
    "PLANNING_STEPS = 10\n",
    "gamma = 0.9\n",
    "s = state = np.array([1000, 1000, 1000, 1000])\n",
    "action_space = np.array([0,1,2])\n",
    "\n",
    "for round in N_ROUNDS:\n",
    "\n",
    "    s_prime, r = true_transition(s, np.random.choice(action_space))\n",
    "\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        t_sa = T(s,a)\n",
    "        r_sa = R(s,a)\n",
    "    \n",
    "    w_t = w_t - alpha_t*(t_sa-s_prime)*tape.gradient(t_sa, w_t)\n",
    "    w_r = w_r - alpha_r*(r_sa - r)*tape.gradient(r_sa, w_r)\n",
    "\n",
    "    # planning\n",
    "    for i in PLANNING_STEPS:\n",
    "        s_hat = None\n",
    "        a_hat = None\n",
    "\n",
    "        with tf.GradientTape() as gt:\n",
    "            q_val = Q(s_hat, a_hat)\n",
    "\n",
    "\n",
    "        delta = R(s_hat, a_hat) + gamma * Q(T(s_hat, a_hat), a_hat_prime)\n",
    "        w_q = w_q - alpha_q*delta*gt.gradient(q_val, w_q)\n",
    "    \n",
    "    s = s_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
