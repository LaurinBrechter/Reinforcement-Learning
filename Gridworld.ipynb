{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple gridworld environment for testing RL algorithms in discrete action and state spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridEnv():\n",
    "    def __init__(self) -> None:\n",
    "        self.grid = np.ones((10,10)) * -1\n",
    "        self.grid[0, 1:-1] = -10\n",
    "        \n",
    "    def reset(self):\n",
    "        self.player_position = [0,0]\n",
    "    \n",
    "    def step(self, action): # up=1, down=2, left=3, right=4\n",
    "\n",
    "        next_state = self.player_position\n",
    "        if action == \"up\":\n",
    "            if next_state[0] != 0:\n",
    "                next_state[0] -= 1\n",
    "        elif action == \"down\":\n",
    "            if next_state[0] != 9:\n",
    "                next_state[0] += 1 \n",
    "        elif action == \"left\":\n",
    "            if next_state[1] != 0:\n",
    "                next_state[1] -= 1\n",
    "        elif action == \"right\":\n",
    "            if next_state[1] != 9:\n",
    "                next_state[1] += 1\n",
    "\n",
    "        reward = self.grid[tuple(next_state)]\n",
    "        done = True if self.player_position == [0,9] else False\n",
    "\n",
    "        return next_state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy():\n",
    "    return np.random.choice([\"left\", \"right\", \"up\", \"down\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridEnv()\n",
    "\n",
    "N = 10\n",
    "all_rewards = []\n",
    "\n",
    "for _ in range(N):\n",
    "    env.reset()\n",
    "    done = False\n",
    "\n",
    "    rewards = []\n",
    "    n = 0\n",
    "    n_max = 100\n",
    "    while not done and n < n_max:\n",
    "        n += 1\n",
    "        action = random_policy()\n",
    "\n",
    "        next_state, reward, done = env.step(action)\n",
    "        rewards.append(reward)\n",
    "\n",
    "    all_rewards.append(rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.17, -1.72, -3.88, -2.98, -2.89, -2.08, -1.99, -2.26, -1.27, -1.99]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sum(arr)/len(arr) for arr in all_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
